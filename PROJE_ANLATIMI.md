# 4 Mini Projeyi AdÄ±m AdÄ±m AnlattÄ±m

Bu dokÃ¼manda yaptÄ±ÄŸÄ±m dÃ¶rt mini projeyi kendi aÄŸzÄ±mdan, adÄ±m adÄ±m anlatÄ±yorum. AmacÄ±m klasik bilgisayarlÄ± gÃ¶rÃ¼ ile derin Ã¶ÄŸrenme Ã§Ä±karÄ±mÄ±nÄ± Ã¶ÄŸrenmekti.

---

## ğŸ”¹ Proje 1: GÃ¶rÃ¼ntÃ¼ BenzerliÄŸi (ORB Keypoints)

**Dosya:** `project_1_similarity.py`

**Ne yapmak istedim?**
Ä°ki fotoÄŸrafÄ±n aynÄ± nesneyi gÃ¶sterip gÃ¶stermediÄŸini anlamak istedim. Mesela aynÄ± binanÄ±n iki farklÄ± aÃ§Ä±dan Ã§ekilmiÅŸ fotoÄŸrafÄ± mÄ±, yoksa tamamen farklÄ± iki bina mÄ±?

### AdÄ±mlarÄ±m:

**1. Ã–nce iki gÃ¶rÃ¼ntÃ¼yÃ¼ yÃ¼kledim:**
```python
img1 = load_image_bgr(args.image1)
img2 = load_image_bgr(args.image2)
```
`load_image_bgr` fonksiyonumu kullandÄ±m. Bu fonksiyon Unicode karakterli yollarda bile Ã§alÄ±ÅŸÄ±yor Ã§Ã¼nkÃ¼ `cv2.imdecode` fallback'i var.

**2. GÃ¶rÃ¼ntÃ¼leri gri tona Ã§evirdim:**
```python
gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
```
ORB algoritmasÄ± tek kanallÄ± gÃ¶rÃ¼ntÃ¼ istiyor. Renk bilgisine ihtiyacÄ±m yok, sadece yoÄŸunluk deÄŸerleri yeterli.

**3. ORB dedektÃ¶rÃ¼nÃ¼ oluÅŸturdum:**
```python
orb = cv2.ORB_create(nfeatures=2000)
```
ORB'u seÃ§tim Ã§Ã¼nkÃ¼:
- HÄ±zlÄ± Ã§alÄ±ÅŸÄ±yor
- Patentsiz (SIFT gibi deÄŸil)
- `nfeatures=2000` ile en fazla 2000 anahtar nokta bulmasÄ±nÄ± sÃ¶yledim

**4. Her gÃ¶rÃ¼ntÃ¼de keypoint ve tanÄ±mlayÄ±cÄ±larÄ± Ã§Ä±kardÄ±m:**
```python
kp1, desc1 = orb.detectAndCompute(gray1, None)
```
Burada iki ÅŸey elde ettim:
- `kp1`: Anahtar noktalarÄ±n koordinatlarÄ±, aÃ§Ä±larÄ±, boyutlarÄ±
- `desc1`: Her keypoint iÃ§in 32 baytlÄ±k ikili tanÄ±mlayÄ±cÄ± (parmak izi gibi dÃ¼ÅŸÃ¼n)

**5. TanÄ±mlayÄ±cÄ±larÄ± eÅŸleÅŸtirdim:**
```python
matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)
knn_matches = matcher.knnMatch(desc1, desc2, k=2)
```
Neden Hamming mesafesi? Ã‡Ã¼nkÃ¼ ORB ikili tanÄ±mlayÄ±cÄ± Ã¼retiyor, Hamming bit farklarÄ±nÄ± sayÄ±yor.
Neden `k=2`? Lowe oran testi iÃ§in en yakÄ±n iki eÅŸleÅŸmeyi almam gerekiyordu.

**6. Lowe oran testini uyguladÄ±m:**
```python
for m, n in knn_matches:
    if m.distance < args.ratio * n.distance:
        good.append(m)
```
Bu testin mantÄ±ÄŸÄ± ÅŸu: EÄŸer en iyi eÅŸleÅŸme (m) ikinci en iyiden (n) belirgin ÅŸekilde daha iyiyse, bu gÃ¼venilir bir eÅŸleÅŸmedir. Yoksa muhtemelen gÃ¼rÃ¼ltÃ¼dÃ¼r.

**7. Sonucu deÄŸerlendirdim:**
```python
similarity_score = len(good)
if similarity_score >= args.min_matches:
    print("SonuÃ§: BENZER")
```
Ä°yi eÅŸleÅŸme sayÄ±sÄ± benim benzerlik skorum oldu. 20'nin Ã¼stÃ¼ndeyse "BENZER" dedim.

### Bu projeden ne Ã¶ÄŸrendim?
- Keypoint: GÃ¶rÃ¼ntÃ¼deki ayÄ±rt edici noktalardÄ±r (kÃ¶ÅŸeler, bloblar)
- Descriptor: O noktanÄ±n sayÄ±sal parmak izi
- Bu yÃ¶ntem derin Ã¶ÄŸrenme **deÄŸil**; elle tasarlanmÄ±ÅŸ Ã¶zellikler kullanÄ±yor
- IÅŸÄ±k ve aÃ§Ä± deÄŸiÅŸiminde zorlanÄ±yor â€” bu normal

---

## ğŸ”¹ Proje 2: Kural TabanlÄ± SÄ±nÄ±flandÄ±rma (Kenar SayÄ±mÄ±)

**Dosya:** `project_2_edges.py`

**Ne yapmak istedim?**
Bir rafÄ±n fotoÄŸrafÄ±na bakÄ±p "boÅŸ mu dolu mu?" sorusuna cevap vermek istedim. Ama CNN kullanmadan, basit bir kuralla.

### AdÄ±mlarÄ±m:

**1. GÃ¶rÃ¼ntÃ¼yÃ¼ yÃ¼kleyip gri yaptÄ±m:**
```python
img = load_image_bgr(args.image)
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
```

**2. Gaussian blur uyguladÄ±m:**
```python
ksize = max(3, args.blur | 1)
blurred = cv2.GaussianBlur(gray, (ksize, ksize), 0)
```
Neden blur? GÃ¼rÃ¼ltÃ¼yÃ¼ azaltmak iÃ§in. Yoksa Canny her yerde sahte kenarlar buluyor.
`| 1` hilesini kullandÄ±m: bu bit iÅŸlemi Ã§ift sayÄ±yÄ± tek yapÄ±yor (OpenCV tek kernel istiyor).

**3. Canny kenar tespiti yaptÄ±m:**
```python
edges = cv2.Canny(blurred, args.canny_low, args.canny_high)
```
Canny'nin iki eÅŸiÄŸi var:
- Alt eÅŸik (50): Bunun altÄ±ndaki gradyanlar kenar deÄŸil
- Ãœst eÅŸik (150): Bunun Ã¼stÃ¼ndekiler kesinlikle kenar
- Aradakiler: GÃ¼Ã§lÃ¼ kenarlara baÄŸlÄ±ysa kenar sayÄ±lÄ±r

**4. Kenar piksellerini saydÄ±m:**
```python
edge_pixels = int(np.count_nonzero(edges))
```
Canny Ã§Ä±ktÄ±sÄ± siyah-beyaz. Beyaz pikseller kenar. `count_nonzero` ile saydÄ±m.

**5. Basit bir kuralla karar verdim:**
```python
label = "NOT EMPTY" if edge_pixels > args.edge_thresh else "EMPTY"
```
EÄŸer kenar sayÄ±sÄ± 500'Ã¼n Ã¼stÃ¼ndeyse rafta bir ÅŸeyler var demektir.

### Bu projeden ne Ã¶ÄŸrendim?
- CNN Ã¶ncesi dÃ¶nemde insanlar Ã¶zellikleri elle tanÄ±mlÄ±yordu
- Bu yÃ¶ntem Ã¶lÃ§eklenmiyor: farklÄ± Ä±ÅŸÄ±k, aÃ§Ä±, nesne tÃ¼rlerinde Ã§uvalladÄ±
- **Ä°ÅŸte bu yÃ¼zden CNN'lere ihtiyaÃ§ var** â€” motivasyonu anladÄ±m

---

## ğŸ”¹ Proje 3: HazÄ±r CNN ile SÄ±nÄ±flandÄ±rma

**Dosya:** `project_3_cnn_ready.py`

**Ne yapmak istedim?**
Ã–n eÄŸitimli bir CNN kullanarak gÃ¶rÃ¼ntÃ¼deki nesneyi tanÄ±mak istedim. Ama model eÄŸitmedim, sadece Ã§Ä±karÄ±m yaptÄ±m.

### AdÄ±mlarÄ±m:

**1. CihazÄ± seÃ§tim:**
```python
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
```
GPU varsa kullan dedim, yoksa CPU'da Ã§alÄ±ÅŸsÄ±n.

**2. Ã–n eÄŸitimli modeli yÃ¼kledim:**
```python
weights = models.MobileNet_V3_Large_Weights.DEFAULT
model = models.mobilenet_v3_large(weights=weights)
model.eval()
```
- `weights=...`: ImageNet Ã¼zerinde eÄŸitilmiÅŸ aÄŸÄ±rlÄ±klarÄ± otomatik indirdi
- `model.eval()`: Dropout ve BatchNorm'u Ã§Ä±karÄ±m moduna aldÄ±m (Ã¶nemli!)

**3. GÃ¶rÃ¼ntÃ¼yÃ¼ modelin beklediÄŸi formata getirdim:**
```python
img_resized = resize_rgb(img_rgb, target_hw[::-1])  # 224x224 yaptÄ±m
tensor = to_torch_tensor(img_resized)               # HWC â†’ CHW, /255 ile normalize ettim
tensor = normalize_tensor(tensor, mean, std)        # ImageNet ortalamasÄ±/std ile normalize ettim
batch = tensor.unsqueeze(0)                         # Batch boyutu ekledim
```
Bu adÄ±mlar zorunlu. Model tam olarak bu formatÄ± bekliyor, yoksa saÃ§ma sonuÃ§lar veriyor.

**4. Ã‡Ä±karÄ±m yaptÄ±m:**
```python
with torch.no_grad():
    outputs = model(batch)
    probs = torch.nn.functional.softmax(outputs, dim=1)[0]
```
- `torch.no_grad()`: Gradyan hesaplamadÄ±m â€” bellek ve hÄ±z kazandÄ±m
- `softmax`: Ham skorlarÄ± olasÄ±lÄ±klara Ã§evirdim (toplamÄ± 1 oldu)

**5. En yÃ¼ksek olasÄ±lÄ±klÄ± sÄ±nÄ±flarÄ± yazdÄ±rdÄ±m:**
```python
scores, indices = torch.topk(probs, topk)
label = categories[idx]
print(f"{rank}. {label}: {score:.3f}")
```

### Bu projeden ne Ã¶ÄŸrendim?
- SÄ±nÄ±flandÄ±rma: "Bu gÃ¶rÃ¼ntÃ¼de ne var?" sorusuna tek cevap verir
- EÄŸitim vs Ã‡Ä±karÄ±m: Ben sadece ileri geÃ§iÅŸ yaptÄ±m, aÄŸÄ±rlÄ±klar gÃ¼ncellenmedi
- Transfer Ã¶ÄŸrenme: BaÅŸkasÄ±nÄ±n (ImageNet'te) eÄŸittiÄŸi modeli kullandÄ±m
- Ã–n iÅŸleme kritik: YanlÄ±ÅŸ normalize edersem model Ã§Ã¶p Ã¼retiyor

---

## ğŸ”¹ Proje 4: SÄ±nÄ±flandÄ±rma vs Nesne Tespiti

**Dosya:** `project_4_compare.py`

**Ne yapmak istedim?**
AynÄ± gÃ¶rÃ¼ntÃ¼de hem sÄ±nÄ±flandÄ±rma hem nesne tespiti yapÄ±p farkÄ± gÃ¶rmek istedim.

### BÃ–LÃœM A â€” SÄ±nÄ±flandÄ±rma YaptÄ±m:

```python
cls_label, cls_score, exists = run_classification(img_rgb)
```
ResNet18 kullandÄ±m. Tek etiket ve gÃ¼ven skoru dÃ¶ndÃ¼. Basit bir eÅŸikle "var/yok" dedim.

### BÃ–LÃœM B â€” Nesne Tespiti YaptÄ±m:

**1. Detection modelini yÃ¼kledim:**
```python
weights = FasterRCNN_ResNet50_FPN_Weights.DEFAULT
model = models.detection.fasterrcnn_resnet50_fpn(weights=weights)
```
Faster R-CNN kullandÄ±m. COCO veri setinde 80 sÄ±nÄ±f Ã¼zerinde eÄŸitilmiÅŸ.

**2. Ã‡Ä±karÄ±m yaptÄ±m:**
```python
batch = [tensor.to(device)]  # Liste olarak verdim!
outputs = model(batch)
```
Ã–nemli bir fark: Detection modelleri giriÅŸ olarak **liste** bekliyor. Ã‡Ã¼nkÃ¼ farklÄ± boyutlu gÃ¶rÃ¼ntÃ¼ler olabilir.

**3. Ã‡Ä±ktÄ±yÄ± Ã§Ã¶zÃ¼mledim:**
```python
boxes = out["boxes"]   # Her nesne iÃ§in [x1, y1, x2, y2] koordinatlarÄ±
scores = out["scores"] # Her kutu iÃ§in gÃ¼ven skoru
labels = out["labels"] # Her kutu iÃ§in sÄ±nÄ±f indeksi
```
SÄ±nÄ±flandÄ±rmadan farklÄ± olarak burada **birden fazla nesne** ve **konum bilgisi** var.

**4. KutularÄ± Ã§izdim:**
```python
drawn = draw_boxes(img, boxes, labels, scores, score_thresh=0.5)
```
Skor eÅŸiÄŸinin Ã¼stÃ¼ndeki tespitler iÃ§in dikdÃ¶rtgen ve etiket Ã§izdim.

### Ä°ki yaklaÅŸÄ±mÄ± karÅŸÄ±laÅŸtÄ±rdÄ±m:

| Ã–zellik | SÄ±nÄ±flandÄ±rma | Nesne Tespiti |
|---------|---------------|---------------|
| Ã‡Ä±ktÄ± | Tek etiket | Birden fazla kutu + etiket |
| Konum bilgisi | Yok | Bounding box koordinatlarÄ± var |
| Soru | "Bu ne?" | "Nerede ne var?" |
| Hesaplama maliyeti | Daha hafif | Ã‡ok daha aÄŸÄ±r |

### Bu projeden ne Ã¶ÄŸrendim?
- SÄ±nÄ±flandÄ±rma sadece "var/yok" diyor, nerede olduÄŸunu sÃ¶ylemiyor
- Detection hem sÄ±nÄ±fÄ± hem konumu veriyor
- Detection Ã§ok daha fazla hesaplama gerektiriyor (FPN, RPN, NMS aÅŸamalarÄ± var)
- KullanÄ±m senaryosuna gÃ¶re doÄŸru olanÄ± seÃ§meliyim

---

## ğŸ¯ Genel Ã–zet

```
GÃ¶rÃ¼ntÃ¼
   â”‚
   â”œâ”€â–º Proje 1: Keypoint Ã§Ä±kardÄ±m â†’ EÅŸleÅŸtirdim â†’ Benzerlik skoru aldÄ±m
   â”‚
   â”œâ”€â–º Proje 2: Blur â†’ Canny â†’ Piksel saydÄ±m â†’ Kural ile karar verdim
   â”‚
   â”œâ”€â–º Proje 3: Resize â†’ Normalize â†’ CNN â†’ Softmax â†’ Top-K etiket aldÄ±m
   â”‚
   â””â”€â–º Proje 4: â”¬â”€ SÄ±nÄ±flandÄ±rma â†’ "Var/Yok" dedim
                â””â”€ Detection â†’ Kutular Ã§izdim + Etiketler yazdÄ±m
```

## Sonraki AdÄ±mlarÄ±m

1. **YOLO denemeliyim** â€” Faster R-CNN'den daha hÄ±zlÄ±
2. **Kendi veri setimle fine-tuning yapmalÄ±yÄ±m** â€” Transfer Ã¶ÄŸrenmeyi pratiÄŸe dÃ¶kmeliyim
3. **Segmentasyon Ã¶ÄŸrenmeliyim** â€” Kutu yerine piksel bazlÄ± maske

---


